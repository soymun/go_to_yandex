# Оптимизация запросов

Когда вы отправляете SQL-запрос в PostgreSQL (например, `SELECT * FROM users WHERE registration_date > '2023-01-01'`), база данных не выполняет его "в лоб". Вместо этого в дело вступает специальный компонент — **планировщик запросов (Query Planner)**, он же **оптимизатор**.

Его задача — найти самый эффективный способ (план выполнения) для получения данных, которые вы запросили. "Эффективный" здесь означает "самый дешевый" с точки зрения внутренних ресурсов: дискового ввода-вывода (I/O), процессорного времени и т.д.

Процесс выглядит так:

1. **Парсинг (Parsing):** SQL-запрос проверяется на синтаксические ошибки и превращается во внутреннее представление — дерево запроса.
2. **Переписывание (Rewriting):** Правила и представления (views) "разворачиваются". Например, если вы делаете запрос к `view`, система подставит в дерево запроса тот `SELECT`, который определяет это `view`.
3. **Планирование (Planning):** Это самый главный этап. Планировщик генерирует множество возможных планов выполнения запроса и, основываясь на статистике данных и своей модели стоимости, выбирает самый "дешевый".


# Статистика и стоимость

Планировщик — не волшебник. Он принимает решения на основе данных. Главный источник этих данных — **статистика таблиц**.

Статистика - Это информация о распределении данных в ваших таблицах:
    - Количество строк в таблице.
    - Количество уникальных значений в столбце (кардинальность).
    - Наиболее частые значения.
    - Гистограмма распределения значений.
Она собирается командой `ANALYZE`. К счастью, в современных версиях PostgreSQL работает **`autovacuum`**, который автоматически запускает `VACUUM` и `ANALYZE` для таблиц, которые часто изменяются. Без актуальной статистики планировщик слеп. Он может решить, что `WHERE user_id = 123` вернет половину таблицы, хотя на самом деле вернет одну строку. В результате он выберет полный перебор таблицы (`Seq Scan`) вместо быстрого поиска по индексу (`Index Scan`).

**Стоимость (Cost)** — это абстрактная единица, которой планировщик измеряет "дороговизну" операции. Она не равна миллисекундам. Главный фактор, влияющий на стоимость, — это **дисковый ввод-вывод**, так как чтение с диска на порядки медленнее чтения из памяти.

# `EXPLAIN`

Чтобы понять, _что именно_ делает планировщик и почему запрос работает медленно, используется команда `EXPLAIN`.

## `EXPLAIN`

Показывает _план_ выполнения, который выбрал планировщик, но не выполняет сам запрос.
##  `EXPLAIN ANALYZE`

Это мощнейший инструмент. Он **выполняет** запрос и показывает не только _план_, но и _реальные_ метрики выполнения.
## `EXPLAIN (ANALYZE, BUFFERS)`

Добавляет информацию о работе с буферным кешем. Очень полезно для понимания, сколько данных было прочитано с диска, а сколько из кеша.

- `shared hit` — блок найден в кеше PostgreSQL.
- `shared read` — блок прочитан с диска.

**Цель — максимизировать `hit` и минимизировать `read`.**

# Основные узлы плана выполнения (что читать в `EXPLAIN`)
1. **Сканирование таблиц (Scans):**
    
    - `Seq Scan` (Sequential Scan): Полный перебор таблицы. Эффективен для маленьких таблиц или когда нужно получить большую часть таблицы.
    - `Index Scan`: Поиск по индексу для нахождения указателей на строки в таблице, а затем обращение к таблице за самими данными. Идеально для выборки небольшого процента строк.
    - `Index Only Scan`: То же, что и `Index Scan`, но все необходимые данные берутся _прямо из индекса_, без обращения к основной таблице. Это возможно, если все столбцы в `SELECT` и `WHERE` есть в индексе. Очень быстро.
    - `Bitmap Heap Scan`: Двухэтапная операция. Сначала по одному или нескольким индексам создается "битовая карта" строк, удовлетворяющих условию, а затем по этой карте последовательно считываются нужные страницы из таблицы. Эффективно, когда по нескольким индексам нужно выбрать не очень маленькую, но и не очень большую часть таблицы.

2. **Соединения таблиц (Joins):**
    - `Nested Loop Join`: Для каждой строки из первой (внешней) таблицы ищет совпадения во второй (внутренней) таблице. Очень эффективен, если одна из таблиц маленькая. Часто используется вместе с `Index Scan` по внутренней таблице.
    - `Hash Join`: Строит хеш-таблицу по одной (меньшей) из таблиц в памяти, а затем проходит по второй таблице, проверяя для каждой строки наличие совпадения в хеш-таблице. Идеален для соединения больших таблиц, когда нет подходящих индексов для `Nested Loop` и данные не отсортированы. Требует памяти (`work_mem`).
    - `Merge Join`: Обе таблицы должны быть отсортированы по ключу соединения. Затем планировщик просто "сливает" их, двигаясь по обеим таблицам одновременно. Очень эффективен для соединения больших, уже отсортированных таблиц (например, по выходу из `Index Scan`).

3. **Прочие узлы:**
    - `Sort`: Сортировка данных. Дорогая операция, особенно если данные не помещаются в память (`work_mem`) и сбрасываются на диск.
    - `Aggregate` / `HashAggregate`: Группировка данных для агрегатных функций (`COUNT`, `SUM`, `AVG`). `HashAggregate` строит хеш-таблицу для групп и обычно быстрее.
    - `Limit`: Ограничение количества возвращаемых строк.

---

# Практические методы оптимизации

1. **Индексы — ваше всё.**
    - **B-Tree:** Индекс по умолчанию. Идеален для операторов `=`, `>`, `<`, `>=`, `<=`, `BETWEEN`, `IN`, а также для `LIKE 'префикс%'`.
    - **Частичные индексы (Partial Indexes):** Индексируют не всю таблицу, а только ее часть. Очень мощно.
    - **Индексы по выражениям:** Индексируют результат функции.
    - **Покрывающие индексы (Covering Indexes):** Позволяют выполнять `Index Only Scan`.
    - **Другие типы индексов:**
        - `GIN`: Для полнотекстового поиска, поиска по массивам, JSONB.
        - `GiST`: Для геометрических данных, диапазонов.
        - `BRIN`: Для очень больших таблиц с данными, которые физически упорядочены (например, по дате логов).

2. **Пишите "хорошие" запросы.**
    - **Избегайте `SELECT *`**: Выбирайте только те столбцы, которые вам нужны. Это уменьшает I/O и позволяет использовать `Index Only Scan`.
    - **Избегайте функций над индексированными столбцами:** Запрос `WHERE lower(email) = 'test@test.com'` не будет использовать обычный индекс по `email`. Вместо этого используйте индекс по выражению (см. выше) или тип данных `CITEXT` (case-insensitive text).
    - **`JOIN` > подзапросы:** Чаще всего `JOIN` оптимизируется лучше, чем коррелирующий подзапрос в `WHERE`. Но всегда проверяйте через `EXPLAIN`.
    - **`UNION ALL` вместо `UNION`:** Если вам не нужно удалять дубликаты, `UNION ALL` намного быстрее, так как не требует дорогостоящей операции сортировки/хеширования для поиска дублей.

3. **Обслуживание базы данных.**
    - **Следите за статистикой:** Убедитесь, что `autovacuum` работает. Для критичных таблиц можно запускать `ANALYZE` вручную после массовых изменений.
    - **`VACUUM`:** Не только собирает статистику, но и очищает "мертвые" строки, оставшиеся после `UPDATE` и `DELETE`, предотвращая раздувание (bloat) таблиц и индексов.
    - **`REINDEX`:** Если индекс стал сильно "раздутым" и неэффективным, его можно перестроить.

4. **Настройка PostgreSQL (`postgresql.conf`).**
    - `shared_buffers`: Размер кеша PostgreSQL. Обычно 25% от RAM — хорошая отправная точка.
    - `work_mem`: Память, выделяемая на операции сортировки, хеширования. Если ваши запросы сбрасывают данные на диск при сортировке (`Sort Method: external merge Disk`), увеличение этого параметра может помочь.
    - `effective_cache_size`: Подсказка планировщику о том, сколько всего памяти (RAM) доступно для кеширования (включая кеш ОС). Обычно `50-75%` от RAM.

Оптимизация — это не разовая акция, а цикл:

1. **Измерить:** Найти медленный запрос (например, через `pg_stat_statements`).
2. **Проанализировать:** Изучить его план с помощью `EXPLAIN ANALYZE`. Найти "бутылочное горлышко" — самый дорогой узел.
3. **Сформулировать гипотезу:** "Кажется, здесь поможет индекс по полю X" или "Если переписать этот `JOIN`, он станет быстрее".
4. **Проверить:** Создать индекс или переписать запрос в транзакции (чтобы можно было откатить) и снова запустить `EXPLAIN ANALYZE`.
5. **Повторить:** Если стало лучше — закрепить результат. Если нет — откатить изменения и вернуться к шагу 3.
# Индексы

Индексы — это фундаментальный и наиболее частый способ ускорения запросов. В подавляющем большинстве случаев (около 90%) добавление правильного индекса решает проблему производительности.
- **Способы повышения эффективности индексов:**
    1. **Составные (Composite) vs. Одинарные (Single) индексы:** Если в запросе несколько условий в `WHERE`, составной индекс по нескольким столбцам может быть значительно быстрее, чем несколько одинарных. Важно проверять, какой подход лучше работает для конкретного случая.
    2. **Сканирование только по индексу (Index-Only Scan):** Если все столбцы, запрашиваемые в `SELECT`, уже содержатся в самом индексе, базе данных не нужно обращаться к таблице за данными. Это самый быстрый способ чтения.
    3. **Частичные (Partial) индексы:** Это индексы, которые строятся не для всей таблицы, а только для строк, удовлетворяющих определенному условию `WHERE`. Они меньше по размеру и эффективнее, если запросы часто фильтруют данные по одному и тому же статичному критерию (например, `WHERE status = 'active'`).
    4. **Индексы для соединений (JOIN):** Наличие индексов на столбцах, по которым соединяются таблицы, критически важно для быстрого выполнения `JOIN`.

**Селективность** - Показатель уникальности значений в столбце. Чем выше селективность, тем эффективнее индекс.
- **Высокая селективность**: Значения почти уникальны (например, `id`, `email`). Индексы B-Tree или Hash на таких столбцах очень эффективны, так как возвращают мало строк.
- **Низкая селективность**: Мало уникальных значений (например, `пол` или `is_deleted`). Индексы на таких столбцах часто бесполезны, так как планировщик запросов предпочтёт **Seq Scan** (полный просмотр таблицы).
Планировщик PostgreSQL оценивает селективность, чтобы решить, использовать индекс или нет. Например, индекс на булево поле `is_active` (true/false) редко будет полезен, если половина строк имеет значение `true`.

**Обоснованный отказ от использования индексов**

Хотя индексы — мощный инструмент, существуют сценарии, когда их использование нецелесообразно и даже вредно для производительности.

- **Основные причины для отказа от индексов:**
    1. **Маленькая таблица, полностью помещающаяся в память:** Если таблица настолько мала, что СУБД может кэшировать ее целиком в оперативной памяти, последовательное чтение всей таблицы (Full Scan) будет быстрее, чем множественные обращения к индексу, а затем к таблице.
    2. **Запрос выбирает большую часть строк таблицы:** Когда запросу требуется значительный процент данных (например, 30% и более), полный обход таблицы становится более эффективным. Индексный доступ к каждой отдельной строке приведет к большому количеству случайных операций ввода-вывода, что медленнее, чем одно последовательное чтение.
- **Как "запретить" использование индекса:** Иногда оптимизатор СУБД может выбрать индекс там, где это неоптимально. Чтобы этого избежать, можно применить к столбцу преобразование, которое не изменит значение, но сделает индекс неприменимым.

# Длинные запросы

**Длинный запрос** — это не обязательно запрос, который долго выполняется. Это запрос, в котором на каждом этапе обработки (фильтрация, соединение, группировка) передается **большое количество записей**. Он оперирует большими наборами данных.

**Длинные запросы и полное сканирование (Full Scan)**
Для длинных запросов, которые обрабатывают значительную часть таблицы, **полное сканирование является предпочтительным методом доступа к данным.** Причина кроется в физике работы дисков: последовательное чтение большого блока данных (как при Full Scan) требует значительно меньше операций ввода-вывода, чем множество точечных, случайных чтений (как при индексном доступе к разбросанным по таблице строкам). Пороговое значение, при котором Full Scan становится выгоднее, зависит от оборудования (скорости дисков, процессора) и постоянно меняется. PostgreSQL, как правило, самостоятельно и корректно принимает это решение.

**Длинные запросы и соединения хешированием (Hash Join)**
Для соединения больших наборов данных в длинных запросах **соединение хешированием (Hash Join)** является наиболее эффективным алгоритмом. Оно работает быстрее, чем соединение вложенными циклами (Nested Loop), особенно когда таблицы велики.

- **Принцип работы:** СУБД строит в памяти хеш-таблицу по одной (меньшей) из таблиц, а затем сканирует вторую таблицу, находя соответствия через хеш.
- **Условие эффективности:** Алгоритм работает лучше всего, когда хеш-таблица полностью помещается в оперативную память.

**Длинные запросы и порядок соединений**
Даже если в длинном запросе не используются индексы, **порядок соединения таблиц остается критически важным**. Цель — минимизировать размер промежуточных наборов данных. Для этого следует **выполнять самые ограничительные соединения (те, которые сильнее всего сокращают количество строк) в первую очередь.** Хотя оптимизатор СУБД чаще всего сам выбирает правильный порядок, задача разработчика — проверить план выполнения и убедиться, что выбор был оптимальным.

**Полусоединение (Semi-join) и Антисоединение (Anti-join)**

Это особые виды соединений, которые часто реализуются без ключевого слова `JOIN`.
- **Полусоединение:** Возвращает уникальные строки из первой таблицы, для которых нашлось хотя бы одно соответствие во второй. Часто реализуется через оператор `EXISTS`.`
- **Антисоединение:** Возвращает строки из первой таблицы, для которых _не нашлось_ ни одного соответствия во второй. Часто реализуется через `NOT EXISTS`.`

**Длинные запросы: Использование операций над множествами**

Операции над множествами (`UNION`, `INTERSECT`, `EXCEPT`) могут предложить более эффективный и читаемый план выполнения, чем сложные конструкции с `JOIN` и `WHERE`.
- `INTERSECT` — элегантная замена `IN` или `EXISTS`.
- `EXCEPT` — замена `NOT IN` или `NOT EXISTS`.
- `UNION` — замена сложных условий с `OR`.

**Длинные запросы: Избегаем многократного сканирования**

Одна из частых причин медленных запросов — многократное сканирование одной и той же таблицы, что часто вызвано неоптимальным дизайном схемы (например, EAV — Entity-Attribute-Value). Если для получения разных атрибутов одного объекта (например, имени, паспорта, телефона пассажира) вы несколько раз соединяете таблицу с самой собой или с таблицей атрибутов, это крайне неэффективно. Следует переписать запрос так, чтобы он сканировал таблицу только один раз, используя, например, условную агрегацию.

# Временные таблицы

Использование цепочки временных таблиц для разбиения сложного запроса на шаги — плохая практика, так как она создает ряд проблем:

- **Потеря индексов и статистики:** Оптимизатор не может использовать индексы и статистику из исходных таблиц.
- **Нагрузка на диск и I/O:** Временные таблицы записываются на диск, что создает дополнительную нагрузку.
- **Главный недостаток:** Этот подход "фиксирует" порядок выполнения операций. Вы лишаете оптимизатор СУБД возможности найти наилучший план, например, изменив порядок соединений.

# Общие табличные выражения (CTE, `WITH` clause)

Поведение CTE в PostgreSQL сильно зависит от версии:

- **До PostgreSQL 12:** CTE всегда _материализовались_, то есть работали как временные таблицы со всеми их недостатками, не давая преимуществ в оптимизации.
- **Начиная с PostgreSQL 12:** Если CTE используется в запросе один раз и не является рекурсивным, оно _встраивается (inlined)_ в основной запрос. Это позволяет оптимизатору рассматривать его как часть единого целого и применять глобальные оптимизации (например, переносить условия `WHERE` внутрь CTE).
- **Управление поведением:** Можно принудительно управлять этим с помощью ключевых слов `WITH ... AS MATERIALIZED` (старое поведение) и `WITH ... AS NOT MATERIALIZED` (новое поведение).

# Представления (Views)

Представление — это сохраненный запрос. Они удобны для инкапсуляции сложной логики и обеспечения безопасности, но **не дают преимуществ в производительности.** Оптимизатор рассматривает их как "черный ящик", что мешает эффективному планированию, особенно если представление содержит преобразования столбцов. На обычные представления нельзя создавать индексы.

# Материализованные представления (Materialized Views)

Это гибрид представления и таблицы. Они хранят не только сам запрос, но и его **физически сохраненные результаты**.

- **Когда использовать:** Идеально подходят для отчетов и аналитики, где данные не обязаны быть актуальными на 100% в реальном времени.
- **Главное преимущество:** Поскольку данные физически хранятся, на них **можно создавать индексы**, что кардинально ускоряет запросы к ним. Данные нужно периодически обновлять командой `REFRESH`.

# Секционирование (Partitioning)

Секционирование — это разделение одной большой логической таблицы на несколько физических частей (секций) по определенному ключу (чаще всего по диапазону дат или по списку значений). Для длинных запросов, которые часто требуют полного сканирования, это очень полезно. Оптимизатор может определить, что данные нужны только из нескольких секций, и сканировать только их, а не всю гигантскую таблицу.

# Оптимизация модификации данных (DML)

Оптимизация команд `INSERT`, `UPDATE`, `DELETE` состоит из двух частей:

1. **Оптимизация выборки:** Ускорение `SELECT` части команды (например, `WHERE` в `UPDATE` или `INSERT ... SELECT ...`).
2. **Оптимизация записи:** Ускорение непосредственно самого процесса изменения данных. Длительные DML-операции особенно опасны, так как они удерживают блокировки, что может парализовать работу других запросов в системе.

# Функции

В PostgreSQL функции (особенно на PL/pgSQL) **негативно влияют на производительность**, когда вызываются внутри SQL-запроса.

- **Причина:** Оптимизатор рассматривает функцию как **"черный ящик"**. Он не знает, что происходит внутри, и не может встроить ее логику в общий план запроса.
- **Последствия:** Функция вызывается для каждой строки, возвращаемой запросом, вместо того чтобы ее логика была выполнена один раз как часть общего плана. Это приводит к значительному замедлению по сравнению с аналогичным кодом, написанным в виде чистого SQL.

# Пошаговое руководство по оптимизации

1. **Шаг 1: Определите тип запроса.** Он короткий (быстрый отклик, мало данных) или длинный (обработка больших объемов)?
2. **Шаг 2 (для коротких запросов):**
    - Найдите самые ограничительные условия фильтрации.
    - Убедитесь, что под эти условия **существуют и используются индексы**.
    - Стройте запрос, начиная с самой маленькой таблицы (после фильтрации).
3. **Шаг 3 (для длинных запросов):**
    - Подумайте, можно ли перейти на **инкрементальное обновление** данных вместо полного пересчета каждый раз.
    - Если инкрементальное обновление невозможно:
        - Найдите **самое ограничительное соединение** и убедитесь, что оно выполняется первым.
        - Убедитесь, что большие таблицы **сканируются только один раз**.
        - Отложите **группировку и агрегацию (`GROUP BY`) на самый последний шаг** запроса.