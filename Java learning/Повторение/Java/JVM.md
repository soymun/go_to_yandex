# [[Оглавление]]

# Поток

Поток — это поток выполнения программы. JVM поддерживает одновременное выполнение нескольких потоков. В Hotspot JVM Java-поток соответствует native-потоку ОС. После создания Java-потока (с thread-local хранилищем, буферами, объектами синхронизации, стеками и счётчиками) создаётся native-поток. ОС распределяет потоки на процессоры. После инициализации native-поток вызывает метод run() Java-потока. При завершении run() обрабатываются неперехваченные исключения, и native-поток проверяет, нужно ли завершить JVM (например, если завершился последний non-daemon поток). После завершения потока все ресурсы освобождаются.
# Программный счётчик

Если метод — нативный, программный счётчик (ПС) не определён, так как выполнение происходит вне JVM. В остальных случаях ПС содержит адрес текущей инструкции (или опкода). ПС, присущий всем процессорам, инкрементируется после каждой инструкции, указывая на адрес следующей инструкции. JVM использует ПС для отслеживания выполнения инструкций, указывая на адрес в области методов в памяти.
# Стек и Native Стек

Каждый поток имеет собственный стек, где хранятся фреймы методов, выполняющихся в этом потоке. Стек — это LIFO-структура (последний вошёл — первый вышел), поэтому текущий метод находится на вершине. При вызове метода создаётся новый фрейм.

Стек не модифицируется напрямую, кроме операций добавления (push) и удаления (pop) фреймов. Фреймы могут размещаться в куче (Heap), и память для них не обязана быть непрерывной.

Не все JVM поддерживают нативные методы, но те, что поддерживают, создают нативный стек для каждого Java-потока. Если JVM использует C-linkage модель для JNI, нативный стек аналогичен стеку в C, с таким же порядком аргументов и возвращаемым значением, как в программах на C. Нативный метод (в зависимости от реализации JVM) может вызывать Java-метод, при этом выполнение переходит на Java-стек, где создаётся новый фрейм, а нативный стек временно покидается.

# Фрейм

Новый фрейм создаётся и добавляется (push) на вершину стека при вызове метода. Фрейм удаляется (pop), когда метод завершается штатно или при возникновении необработанного исключения. 

Каждый фрейм содержит:

- Массив локальных переменных
- Возвращаемое значение
- Стек операндов
- Ссылку на runtime constant pool класса текущего метода

# Массив локальных переменных

Массив локальных переменных содержит все переменные, необходимые для выполнения метода: ссылку на `this` (для методов экземпляра), параметры метода и другие локальные переменные. Для статических методов параметры начинаются с нулевого слота, а для методов экземпляра нулевой слот зарезервирован для `this`.

Локальные переменные могут быть типов: `boolean`, `byte`, `char`, `long`, `short`, `int`, `float`, `double`, ссылка (`reference`), адрес возврата (`returnAddress`).

Все типы занимают один слот в массиве, кроме `long` и `double`, которые занимают два последовательных слота из-за их 64-битного размера.
# Стек операндов

Стек операндов используется при выполнении байт-кода JVM, действуя как регистры общего назначения в процессоре. Большинство инструкций байт-кода оперируют со стеком операндов: добавляют (push), удаляют (pop), дублируют, меняют местами (swap) или выполняют операции, производящие/потребляющие значения. Инструкции, перемещающие данные между массивом локальных переменных и стеком операндов, часты в байт-коде.
# Run-Time Constant Pool

**Run-Time Constant Pool** — динамическая структура в памяти JVM, создаваемая из Constant Pool при загрузке класса в **Metaspace** (Java 8+). Она изменяема и используется во время выполнения программы.

- **Назначение**:
    - Обеспечивает быстрый доступ к константам.
    - Поддерживает динамическое связывание (dynamic linking) классов, методов и полей.
    - Хранит интернированные строки и разрешённые ссылки.

# JDK, JRE, JVM, JIT

- **JVM** = спецификация
- **JRE** = реализация JVM + JIT-compiler + библиотеки
- **JDK** = JRE + инструменты разработки

# Области памяти в JVM

Виртуальная машина во время исполнения программы использует несколько типов областей памяти (runtime data areas), часть из которых общая для всех потоков, а часть – индивидуальна для каждого потока. В JVM (как и начиная с Java 8+) организация памяти включает следующие сегменты:

- **Heap (куча)** – основная область динамической памяти. В ней выделяется память под все объекты и массивы во время выполнения программы. Куча одна и общая для всех потоков JVM. Здесь размещаются экземпляры классов (объекты) и их нестатические поля. Куча является управляемой сборщиком мусора (GC). Размер кучи может меняться (расширяться/сжиматься) в пределах, указанных параметрами запуска (-Xms – начальный размер, -Xmx – максимальный размер). JVM по умолчанию использует алгоритм Generational Heap – делит кучу на поколения (молодое и старое), что оптимизирует сборку мусора (подробнее в разделе GC).
- **Метод area (методовая область)** – область, где JVM хранит метаданные загруженных классов: структуры классов, методы (байт-код), поля, константы, статические переменные и т.д. В HotSpot начиная с Java 8 методовая область реализована как Metaspace в нативной памяти (вне основной кучи). Эта область тоже общая для всех потоков. При загрузке нового класса JVM резервирует память в Metaspace для его описания. Размер Metaspace по умолчанию не жёстко ограничен (автоматически расширяется по потребности, ограничен лишь памятью процесса, но можно задать -XX:MaxMetaspaceSize). В JVM Metaspace улучшен по сравнению с прежней PermGen: нет фиксированного лимита по умолчанию, уменьшается вероятность OutOfMemoryError при загрузке большого количества классов.
- **Stack (стек потоков)** – у каждого потока исполнения (Java Thread) есть собственный стек JVM. В стеке хранятся кадры (stack frames) для вызванных методов, включая локальные переменные, параметры, промежуточные вычисления операндов и ссылки на пула констант класса. Каждый вызов метода помещает на стек новый фрейм, по завершении метода фрейм уничтожается. Глубина стека может быть настроена (-Xss), переполнение вызывает StackOverflowError. Стек также используется при исключениях (размотка стека). Кроме Java-стека, HotSpot выделяет Native Stack (стек native-методов) для каждого потока, где выполняется код на C/C++ или через JNI.
- **PC-регистр** – каждый поток имеет регистр счётчика программы (Program Counter), указывающий текущую исполняемую инструкцию байт-кода. Для native-потоков PC не определён (так как выполнение не управляется JVM). PC-регистр нужен JVM для отслеживания позиции исполнения, особенно при переключении контекста между потоками.
- **Кодовый кэш** – отдельная область памяти, где HotSpot хранит сгенерированный JIT-компилятором машинный код методов. Кодовый кэш (Code Cache) находится вне кучи (в native памяти процесса). Его размер ограничен флагами (ReservedCodeCacheSize, по умолчанию порядка нескольких МБ). При переполнении код-кэша JIT-компиляция может приостанавливаться. В JVM кодовый кэш используется для оптимизированного Tiered-компилированного кода, профилированного кода и даже может хранить AOT-компилированные фрагменты (если используется JAOTC или Graal AOT в ранних версиях, хотя в Java 21 встроенный AOT уже удалён, об этом позже).
- **Прочие области** – кроме вышеперечисленного, HotSpot использует «вне-heapовую память» (native heap) для своих внутренних структур, JIT-компиляторов (например, Graal JIT, если подключён, выделяет структуры в C-heap), буферов прямой памяти (NIO DirectByteBuffers) и т.д. Например, «C-Heap» упоминается как память, которую HotSpot запрашивает у ОС под собственные нужды (JVM code, internal structures, профайлеры и пр.).

Итоговая картина памяти JVM: при запуске JVM ОС выделяет процессу область адресного пространства, внутри которого JVM организует описанные сегменты – Heap (с разделением на поколения), Metaspace, Code Cache, стеки потоков и др. Некоторые области (heap, stacks) управляются автоматически GC и средой исполнения. На диаграмме ниже показано упрощённое разделение памяти на молодое/старое поколения кучи и область PermGen (в современных версиях заменена Metaspace):

Молодое поколение (Young Gen) разделено на Eden и Survivor (S0, S1), старое поколение (Old Memory) хранит долгоживущие объекты. В Java 8+ PermGen была удалена, метаданные классов хранятся в Metaspace вне кучи. Стрелками показаны сборки: Minor GC освобождает молодое поколение, Major GC – старшее; параметры -Xms/-Xmx задают размер кучи, -XX:MaxPermSize – старой PermGen (устаревший параметр).

Методическая область (PermGen/Metaspace) на диаграмме обозначена справа. В Java 21 Metaspace автоматически расширяется при загрузке большого числа классов, а при выгрузке классов (например, в контейнерах классов) может освобождать память ОС, чего не умел PermGen. За счёт этого улучшена управляемость памяти JVM в длительно работающих приложениях.

# Execution Engine

Execution Engine – механизм выполнения байт-кода – состоит из интерпретатора, одного или нескольких JIT-компиляторов, а также включает модуль Garbage Collection и интерфейс для вызова native-методов (JNI). В HotSpot VM исторически существуют два основных JIT-компилятора: C1 (Client Compiler) и C2 (Server Compiler), каждый оптимизирован под разные задачи. В современных сборках HotSpot они работают совместно в режиме Tiered Compilation (многоуровневая компиляция) для достижения баланса между скоростью запуска и максимальной производительностью.

- **Интерпретатор** – компонент, который запускает байт-код посредством построчной интерпретации. При интерпретации выполняется цикл: прочитать очередную инструкцию байт-кода метода, выполнить соответствующую последовательность машинных инструкций (реализующих эту семантику), затем перейти к следующей инструкции. Интерпретатор не выполняет межинструкционных оптимизаций – он просто «словари» байт-код в машинные команды на лету. Преимущество интерпретатора – моментальный старт: любой метод сразу может быть исполнен, не тратя время на компиляцию. Недостаток – медленная работа горячих участков кода, так как каждый вызов метода интерпретируется заново (если не подключается JIT).
    
- **JIT-компиляторы (Just-In-Time)** – компилируют горячие методы или участки байт-кода в высокопроизводительный машинный код непосредственно во время работы приложения. HotSpot имеет двух-tierовую систему: C1 (быстрый компилятор с меньшими оптимизациями) и C2 (оптимизирующий компилятор с агрессивными оптимизациями). При включённом Tiered Compilation (по умолчанию в JVM) действуют 4 уровня компиляции:
    
    - Tier 0: интерпретируемый код (с профилированием).
    - Tier 1-3: компиляция C1 в нескольких режимах (без профиля, с профилированием и пр.).
    - Tier 4: максимальные оптимизации C2.
    
    Такой подход позволяет сначала быстро скомпилировать часто вызываемый метод с помощью C1, получив умеренное ускорение, а при достаточной «нагреве» (числе запусков) – передать его C2 для тщательной оптимизации. Adaptation: C1 может собирать профили выполнения (частоты вызовов, распределение классов для виртуальных вызовов, бранчи) и передавать эти данные C2, чтобы тот сгенерировал максимально эффективный код. HotSpot JIT применяет множество оптимизаций, сходных с оптимизациями в компиляторах C++: развёртка циклов, высвёртывание методов (inlining), устранение общих подвыражений, escape-анализа (определение объектов, не покидающих метод, для размещения их на стеке) и пр. Кроме того, благодаря динамической природе JVM JIT может делать оптимизации на основе профиля: например, спекулятивно предполагать, что определённый виртуальный вызов всегда приходит к единственному классу, и встроить вызов напрямую (devirtualization). Если предположение позже нарушится (появится другой класс), JVM выполнит деоптимизацию – вернётся с машинного кода к интерпретированному исполнению для этого метода, и при необходимости перекомпилирует его заново без неверных допущений. Важная особенность JIT в HotSpot: компиляция выполняется параллельно основному коду, в фоновых потоках-компиляторах. Потому приложение не «стоит» в паузе на время JIT-компиляции, а продолжает выполняться (чаще всего интерпретатором). Однако, пока метод не скомпилирован, он работает медленнее, поэтому слишком долгие компиляции или слишком много компиляций могут влиять на общую производительность (так называемый JIT warmup time – время прогрева JIT).
    
- Разработчики HotSpot давно стремились уменьшить накладные расходы JIT. Например, начиная с Java 7 был введён Tiered режим, позволяющий достичь более плавного разгона производительности: сначала метод сразу интерпретируется (нулевое ожидание), затем достаточно быстро компилируется C1 (небольшая пауза, но ощутимый прирост), а спустя ещё некоторое время – C2 (ещё прирост). В результате, как правило, Java-приложение сначала показывает скромную производительность (cold start), но по мере работы, когда основные методы оптимизированы, выходит на высокий уровень (после warm-up).
    

Современные реализации (включая JVM) также поддерживают альтернативные JIT. Например, Graal JIT – компилятор, написанный на Java (привносится через JVMCI интерфейс, JEP 243). Graal может использоваться вместо C2 и в некоторых случаях генерирует более эффективный код. Однако в JDK 21 Graal не включён по умолчанию – ранее он был экспериментальным и убран из комплектации JDK 17 (JEP 410). Для использования Graal JIT обычно применяют GraalVM или подключают внешне. JVMCI при этом остаётся частью JVM, позволяя сторонним JIT-компиляторам интегрироваться.

- **Интерфейс JNI** – неотъемлемая часть Execution Engine. JNI (Java Native Interface) позволяет JVM вызывать нативные функции, написанные на С/С++ и других языках, и наоборот, даёт native-коду доступ к JVM. При вызове native-метода JVM передаёт управление в Native Method Interface, который использует Native Method Libraries. Это отображено на диаграмме архитектуры (блоки JNI и Native Libraries). Хотя JNI-методы исполняются вне JVM, они влияют на производительность (частые переходы через JNI дорогие) и управление памятью (нативный код должен самостоятельно управлять памятью вне кучи).

# AOT

Помимо JIT, в Java существует концепция Ahead-of-Time (AOT) компиляции – предварительного компилирования байт-кода в машинный код до запуска приложения. Цель AOT – сократить время прогрева и повысить предсказуемость исполнения за счёт отсутствия JIT-пауз. В чистом HotSpot исторически AOT не применялся, однако в JDK 9 был представлен экспериментальный инструмент jaotc (JEP 295) для компиляции выбранных классов заранее. Он использовал компилятор Graal для генерации native-кода, который загружался JVM при старте. Тем не менее, данная функциональность не получила широкого применения и требовала значительных усилий по сопровождению, поэтому к JDK 17 было принято решение её убрать (JEP 410). В Java 21 стандартный HotSpot не поддерживает AOT out-of-the-box. Разработчикам, нуждающимся в AOT, предлагается использовать GraalVM Native Image или иные внешние решения.

GraalVM Native Image – наиболее известное современное решение AOT-компиляции для Java. С его помощью приложение (и все используемые библиотеки) целиком компилируется в машкод на этапе сборки, формируя самодостаточный исполняемый файл. Это обеспечивает мгновенный старт (нет интерпретации и JIT) и очень низкое потребление памяти (не нужен JVM-хран, компиляторы, многие метаданные). Однако есть и минусы: длительное время компиляции, отсутствие некоторых динамических возможностей Java (рефлексия, динамическая загрузка классов – требуют дополнительных манипуляций при сборке), и самое главное – более низкая пиковая производительность в долгосрочной перспективе. Поскольку AOT-компилятор не располагает точным профилем исполнения, он вынужден генерировать более консервативный код. Практика показывает, что высоконагруженные долгоживущие сервисы под управлением классического HotSpot JIT со временем обгоняют по скорости аналогичные AOT-образа. В целом JIT обеспечивает более высокую итоговую производительность за счёт динамических оптимизаций, тогда как AOT выигрывает в быстроте запуска и экономии памяти. Поэтому выбор JIT vs AOT зависит от характера приложения:

- **JIT (HotSpot)** – оптимален для длительно работающих приложений, где важна максимальная скорость выполнения бизнес-логики после прогрева (серверные приложения, сервисы с постоянной нагрузкой). Благодаря адаптивной оптимизации JIT-компиляции код может выполняться быстрее, особенно при сложных профилируемых сценариях. Также JIT полностью поддерживает всю динамику Java (рефлексия, прокси, динамические классы) без дополнительных усилий.
- **AOT (GraalVM Native Image)** – привлекателен для сценариев, требующих мгновенной готовности и малого footprint: Serverless-функции с ограничением холодного старта, небольшие микросервисы в контейнерах, CLI-утилиты, приложения для ограниченных сред. Они запускаются практически моментально и потребляют меньше памяти, хотя на продолжительных вычислениях могут уступать JIT по скорости.

Стоит упомянуть проект OpenJ9 (JVM от Eclipse/IBM), в котором поддерживается AOT в комбинации с профилированием (он может сохранять профили между запусками, аналогично как .NET). Но в контексте стандартного HotSpot/OpenJDK 21 встроенной поддержки AOT нет. Перспективы развития AOT в Java связаны с проектом Leyden, целью которого объявлено улучшение времени старта Java-приложений, возможно путём статической компиляции. Но по состоянию на Java 21 Leyden находится в ранних исследованиях.

Таким образом, архитектура JVM представляет собой развитую систему с адаптивной JIT-компиляцией, эффективным сборщиком мусора и модульной структурой, обеспечивающей высокую производительность и масштабируемость. Далее мы подробнее рассмотрим управление памятью и сборку мусора, а затем процесс запуска JVM, где многие из описанных компонентов взаимодействуют.




# GC

Сборщик мусора (GC) в JVM отвечает за автоматическое освобождение памяти, занятой объектами, которые больше недоступны программе. Это ключевое преимущество Java над языками с ручным управлением памятью: GC избавляет от утечек памяти и ошибок освобождения, обеспечивая более надёжное управление памятью. HotSpot реализует гибкую подсистему GC с поддержкой нескольких алгоритмов, настраиваемых под разные требования по паузам и производительности. Все современные сборщики являются трэссирующими (tracing collectors) – т.е. находят «мусор» путём обхода графа объектов от корней (статические переменные, стеки, регистры) и поиска недостижимых объектов.

**Generational GC (поколения).** HotSpot с ранних версий использует поколений подход: объекты разделяются на молодое поколение (Young) и старшее поколение (Old). Молодое поколение предназначено для короткоживущих объектов: большинство новых объектов возникают и быстро становятся недостижимыми (например, временные объекты в методах). Старшее поколение хранит объекты, пережившие достаточное число циклов сборки (долгоживущие). Такой подход основан на эмпирическом факте, что «большинство объектов умирает молодым». Он позволяет применять разные алгоритмы к разным поколениям, оптимизируя работу:

- **Minor GC** – частая и быстрая сборка, очищающая молодое поколение. Выполняется сравнительно часто, но затрагивает малый объём памяти, поэтому паузы небольшие.
- **Major GC / Full GC** – более редкая, очищает старшее поколение (а иногда и весь heap). Выполняется реже, но может быть более тяжёлой.

Young-поколение в HotSpot itself разделено на Eden и два Survivor пространства (S0, S1). Новый объект сначала выделяется в Eden; при заполнении Eden запускается Minor GC: живые объекты из Eden перемещаются (копируются) в Survivor пространства (один из них, второй пустой), а Eden очищается целиком. Survivor пространства чередуются ролями (копирующий GC). Объекты, несколько раз пережившие Minor GC, перемещаются в старший heap (tenured). Старшее поколение обычно собирается алгоритмом маркировки-сжатия либо инкрементальными алгоритмами.

По умолчанию JVM использует Garbage Collector G1, который также придерживается поколений, но реализует их по-своему.

# G1 GC

Первое, что бросается в глаза при рассмотрении G1 — это изменение подхода к организации кучи. Здесь память разбивается на множество регионов одинакового размера. Размер этих регионов зависит от общего размера кучи и по умолчанию выбирается так, чтобы их было не больше 2048, обычно получается от 1 до 32 МБ. Исключение составляют только так называемые _громадные (humongous) регионы_, которые создаются объединением обычных регионов для размещения очень больших объектов.  
  
Разделение регионов на Eden, Survivor и Tenured в данном случае логическое, регионы одного поколения не обязаны идти подряд и даже могут менять свою принадлежность к тому или иному поколению. Пример разделения кучи на регионы может выглядеть следующим образом (количество регионов сильно приуменьшено):  
  

![Регионы сборщика G1 GC](https://habrastorage.org/r/w1560/files/34d/781/181/34d781181f5e4481be98557899ae0cf2.png)

  
Малые сборки выполняются периодически для очистки младшего поколения и переноса объектов в регионы Survivor, либо их повышения до старшего поколения с переносом в Tenured. Над переносом объектов трудятся несколько потоков, и на время этого процесса работа основного приложения останавливается. Это уже знакомый нам подход из рассмотренных ранее сборщиков, но отличие состоит в том, что очистка выполняется не на всем поколении, а только на части регионов, которые сборщик сможет очистить не превышая желаемого времени. При этом он выбирает для очистки те регионы, в которых, по его мнению, скопилось наибольшее количество мусора и очистка которых принесет наибольший результат. Отсюда как раз название Garbage First — мусор в первую очередь.  
  
А с полной сборкой (точнее, здесь она называется _смешанной (mixed)_) все немного хитроумнее, чем в рассмотренных ранее сборщиках. В G1 существует процесс, называемый _циклом пометки (marking cycle)_, который работает параллельно с основным приложением и составляет список живых объектов. За исключением последнего пункта, этот процесс выглядит уже знакомо для нас:  

1. Initial mark. Пометка корней (с остановкой основного приложения) с использованием информации, полученной из малых сборок.
2. Concurrent marking. Пометка всех живых объектов в куче в нескольких потоках, параллельно с работой основного приложения.
3. Remark. Дополнительный поиск не учтенных ранее живых объектов (с остановкой основного приложения).
4. Cleanup. Очистка вспомогательных структур учета ссылок на объекты и поиск пустых регионов, которые уже можно использовать для размещения новых объектов. Первая часть этого шага выполняется при остановленном основном приложении.

  
Следует иметь в виду, что для получения списка живых объектов G1 использует алгоритм Snapshot-At-The-Beginning (SATB), то есть в список живых попадают все объекты, которые были таковыми на момент начала работы алгоритма, плюс все объекты, созданные за время его выполнения. Это, в частности, означает, что G1 допускает наличие плавающего мусора, с которым мы познакомились при рассмотрении сборщика CMS.  
  
После окончания цикла пометки G1 переключается на выполнение смешанных сборок. Это значит, что при каждой сборке к набору регионов младшего поколения, подлежащих очистке, добавляется некоторое количество регионов старшего поколения. Количество таких сборок и количество очищаемых регионов старшего поколения выбирается исходя из имеющейся у сборщика статистики о предыдущих сборках таким образом, чтобы не выходить за требуемое время сборки. Как только сборщик очистил достаточно памяти, он переключается обратно в режим малых сборок.  
  
Очередной цикл пометки и, как следствие, очередные смешанные сборки будут запущены тогда, когда заполненность кучи превысит определенный порог.  
  
Смешанная сборка мусора в приведенном выше примере кучи может пройти вот так:  
  

![Смешанная сборка в G1 GC](https://habrastorage.org/r/w1560/files/8ee/d12/62d/8eed1262d47a407a9f64f2df8635bdb6.png)

  
Может оказаться так, что в процессе очистки памяти в куче не остается свободных регионов, в которые можно было бы копировать выжившие объекты. Это приводит к возникновению ситуации _allocation (evacuation) failure_, подобие которой мы видели в CMS. В таком случае сборщик выполняет полную сборку мусора по всей куче при остановленных основных потоках приложения.  
  
Опираясь на уже упомянутую статистику о предыдущих сборках, G1 может менять количество регионов, закрепленных за определенным поколением, для оптимизации будущих сборок.  

### Гиганты

  
В начале рассказа о G1 я упомянул о существовании громадных регионов, в которых хранятся так называемые _громадные объекты (humongous objects)_. С точки зрения JVM любой объект размером больше половины региона считается громадным и обрабатывается специальным образом:  

- Он никогда не перемещается между регионами.
- Он может удаляться в рамках цикла пометки или полной сборки мусора.
- В регион, занятый громадным объектом, больше никого не подселяют, даже если в нем остается свободное место.

  
Вообще, эти пункты иногда имеют далеко идущие последствия. Объекты большого размера, особенно короткоживущие, могут доставлять много неудобств всем типам сборщиков, так как не удаляются при малых сборках, а занимают драгоценное пространство в регионах старшего поколения (помните объекты-акселераты, обсуждавшиеся в предыдущей главе?) Но G1 оказывается более уязвимым к их негативному влиянию в силу того, что для него даже объект в несколько мегабайт (а в некоторых случаях и 500 КБ) уже является громадным.

# ZGC

Для достижения своих целей ZGC использует подход, называемый раскрашиванием указателей. На практике это означает, что каждый 64-битный указатель (а ZGC поддерживает только 64-битные системы) содержит не только адрес памяти, но и дополнительные метаданные, определяющие текущий статус указателя.

Под адрес в указателе выделяется от 42 до 44 младших бит в зависимости от установленного максимального размера кучи. Это значит, что ZGC может работать с кучами размером до 16 ТБ (одну из трех поставленных задач уже решили, это было несложно). До версии JDK 13 был вариант только с 42-битными адресами и ограничением на размер кучи 4 ТБ. Мы в данной статье будем рассматривать вариант с 44-битным указателем.

Еще четыре бита выделено под метаданные:

- Marked0 (0001) и Marked1 (0010) — используются для пометки указателей на разных фазах сборки.
    
- Remapped (0100) — указатель помечается этим битом в случае, если адрес в указателе является окончательным и не должен модифицироваться в рамках текущего цикла сборки.
    
- Finalizable (1000) — этим битом помечаются объекты, достижимые только из финализатора.
    

Комбинация этих флагов определяет состояние указателя, которое при описании ZGC называется его "цветом".

А что с остальными 16-ю битами? Они всегда равны нулю и не используются.

В итоге, указатель на объект в памяти JVM при использовании ZGC имеет такую структуру:

![Структура "цветного" указателя](https://habrastorage.org/r/w1560/getpro/habr/upload_files/7da/b15/236/7dab152360259f7536af5cd17cc9677f.png "Структура \"цветного\" указателя")

Теперь давайте объединим это знание с тем, что мы вспомнили про устройство виртуальной памяти. В этом случае нулевой адрес (младшие 44 бита) с тем или иным установленным "красочным" битом будет представлять собой начало 16-терабайтной области в виртуальной памяти. Причем все эти области проецируются на одну и ту же область физической памяти — на кучу JVM:

![Отображение виртуальной памяти на кучу](https://habrastorage.org/r/w1560/getpro/habr/upload_files/9d2/587/ddc/9d2587ddc958cc3fbf776bd27c33cb95.png "Отображение виртуальной памяти на кучу")

Отображение виртуальной памяти на кучу

Это значит, что устанавливая или снимая какой-либо из битов метаданных указателя (перекрашивая указатель), не меняя адреса, мы переносимся в другую область виртуальной памяти, но при этом получаем виртуальный указатель на тот же самый объект, на который ссылались до перекрашивания. Удобно.

## Барьеры

Еще одной особенностью ZGC является использование т. н. _барьеров_ (_barriers_) во время конкурентных фаз сборки мусора (когда сборщик работает одновременно с приложением, не останавливая его выполнение).

Барьер — это просто функция, которая принимает указатель на объект в памяти, анализирует цвет этого указателя, в зависимости от цвета выполняет какие-либо действия с этим указателем или даже с самим объектом, на который он ссылается, после чего возвращает актуальное значение указателя, которое необходимо использовать для доступа к объекту.

Важной особенностью функции-барьера является то, что она выполняется в том числе в рамках основных потоков приложения. То есть сборкой мусора занимаются не только выделенные потоки GC, но и само приложение, чего мы в предыдущих сборщиках не встречали.

Какие конкретно манипуляции барьеры производят с указателями и с объектами, мы рассмотрим ниже. Пока что нам достаточно знаний просто про наличие таких барьеров.

## Поиск живых объектов

Теперь давайте посмотрим, как ZGC использует цветные указатели и барьеры для очистки кучи. Первым этапом работы сборщика является покраска указателей на достижимые объекты.

Для иллюстрации работы ZGC будем использовать пример из презентации Oracle. Начинается всё с такого расположения и состояния объектов:

![Начальное состояние кучи](https://habrastorage.org/r/w1560/getpro/habr/upload_files/6a2/114/18e/6a211418e0bbe2e269ab2847cecacc3f.png "Начальное состояние кучи")

Начальное состояние кучи

Дальше в описании мы будем раскрашивать указатели разными цветами в соответствии с состоянием их метаданных. Для наглядности объекты тоже будем раскрашивать.

Этап поиска живых объектов и первоначальной раскраски ссылок состоит из трех фаз:

**Фаза Pause Mark Start**

Сборка мусора, как обычно, начинается с поиска живых объектов. А поиск живых объектов, как обычно, начинается с поиска объектов, достижимых из корней. Для этого ZGC использует короткую STW-паузу. Если вы не понимаете что-то в этих трех предложениях, лучше еще раз перечитать как минимум [первую статью](https://habr.com/ru/post/269621/) данного цикла

Особенностью ZGC является то, что в процессе обхода кучи он не только определяет, какие из объектов являются живыми, но и попутно красит указатели, по которым путешествует, устанавливая у них один из битов Marked0 или Marked1.

На этом этапе выберем красный цвет для раскрашивания ссылок, по которым мы добирались до живых объектов. В результате получаем такую картину:

![После пометки корней](https://habrastorage.org/r/w1560/getpro/habr/upload_files/a89/b92/849/a89b92849a5869614bae3b93c38ce21d.png "После пометки корней")

После пометки корней

**Фаза Concurrent Map**

После того, как найдены все объекты, достижимые из корней, работа приложения возобновляется и начинается вторая фаза сборки, в которой сборщик продолжает поиск живых объектов, достижимых из найденных корней, но уже в конкурентном режиме.

Так как во время этой фазы приложение работает и может создавать новые объекты, в этот период активно используются барьеры, которые красят все указатели, по которым в это время производится доступ к объектам.

**Фаза Pause Mark End**

После завершения конкурентной фазы опять возникает пауза STW, в рамках которой ZGC обрабатывает различные специальные кейсы. В частности, soft- и weak-references.

В результате все указатели на живые объекты оказываются раскрашенными, а все объекты, до которых можно добраться по таким указателям, являются достижимыми:

![После пометки всех живых объектов](https://habrastorage.org/r/w1560/getpro/habr/upload_files/292/a30/81a/292a3081a9db851863ff768704922424.png "После пометки всех живых объектов")

После пометки всех живых объектов

## Перемещение

Следующий этап в работе ZGC — это перемещение объектов для дефрагментации и высвобождения памяти. Данный этап так же разбит на несколько фаз:

**Фаза Concurrent Prepare for Relocate**

В рамках этой активности сборщик определяет блоки памяти, объекты из которых подлежат перемещению. Эти блоки попадают в так называемый _набор для перемещения_ (_relocation set_).

В такой набор заносятся блоки, в которых находится достаточно много мертвых объектов, чтобы их перемещение приносило пользу:

![Выбраны блоки для перемещения](https://habrastorage.org/r/w1560/getpro/habr/upload_files/e35/1af/68c/e351af68c579ddcb524aca3c7fcf7d87.png "Выбраны блоки для перемещения")

Выбраны блоки для перемещения

**Фаза Pause Relocate Start**

Дальше начинается непосредственно перемещение объектов. Как и их поиск, перемещение начинается с объектов, достижимых из корней, и производится в рамках паузы STW.

Если объект достижим по указателю из корня и подлежит перемещению, он переносится в новый блок памяти, корневой указатель на него красится и сборщик запоминает соответствие старого и нового адреса перемещенного объекта в специальных _таблицах переадресации_ (_forwarding tables_). Такие таблицы ведутся отдельно для каждого блока в памяти за пределами кучи.

Корневые указатели на объекты, не подлежащие перемещению, просто перекрашиваются в тот же цвет.

![После перемещения корневых объектов](https://habrastorage.org/r/w1560/getpro/habr/upload_files/9e8/aac/b55/9e8aacb5517e52baed98346c49b9e935.png "После перемещения корневых объектов")

После перемещения корневых объектов

**Фаза Concurrent Relocate**

Эта фаза распространяет описанную выше активность переноса объектов (вместе с ведением таблицы переходов) на оставшуюся кучу.

Как следует из названия, происходит она в конкурентном режиме, одновременно с работой приложения. А это значит, что в рамках нее активно используются барьеры. Но эти барьеры выполняют уже не только раскраску указателей, но и физическое перемещение объектов если они обнаружили доступ по указателю к объекту, подлежащему перемещению, но еще не перемещенному.

Например, без работы барьеров картина после данной фазы выглядела бы вот так:

![Объекты перенесены, но указатели не перекрашены](https://habrastorage.org/r/w1560/getpro/habr/upload_files/329/d4a/fc6/329d4afc6de5f086eca70757e8e01ee4.png "Объекты перенесены, но указатели не перекрашены")

Объекты перенесены, но указатели не перекрашены

Но если в течение этой фазы приложение попыталось получить объект 5 по устаревшему указателю из объекта 4, то барьер корректно перенаправит и перекрасит этот указатель:

![Указатель перекрашен барьером](https://habrastorage.org/r/w1560/getpro/habr/upload_files/f4c/a8b/f47/f4ca8bf474dc9ae3c62033f26768cbcc.png "Указатель перекрашен барьером")

Указатель перекрашен барьером

**Фаза Concurrent Remap**

После окончания предыдущей фазы все объекты оказываются перемещенными в целевые области памяти и единственное, что отделяет нас от окончательной целевой картины, это зависшие указатели на объекты в освобожденных регионах памяти (они остались красными на схеме).

Чтобы поправить все такие указатели, необходимо совершить еще один обход графа объектов, проследовав по всем указателям и перенаправив их на новые адреса в соответствии с таблицами переадресации. Но ZGC не выполняет эту фазу сразу в рамках текущего цикла сборки, а совмещает ее с фазой Concurrent Mark следующего цикла сборки. То есть фазы в разных циклах сборки накладываются друг на друга:

![Организация фаз внутри циклов сборки](https://habrastorage.org/r/w1560/getpro/habr/upload_files/6d4/f19/236/6d4f1923601d31f4ce7ee68007128c0b.png "Организация фаз внутри циклов сборки")

Организация фаз внутри циклов сборки

После фазы Pause Mark Start следующего цикла сборки будут помечены объекты, достижимые из корней:

![После пометки корней в следующем цикле сборки](https://habrastorage.org/r/w1560/getpro/habr/upload_files/281/a20/18c/281a2018c018015c74400d9a722e2a4b.png "После пометки корней в следующем цикле сборки")

После пометки корней в следующем цикле сборки

И далее в рамках фазы Concurrent Mark коллектор пройдется по всем оставшимся указателям, обнаружит несоответствие их цветов (красные) текущей фазе сборки (синий) и поправит. Либо сама программа, получая объекты по таким зависшим указателям и вызывая срабатывание барьеров, будет перемещать объекты и перекрашивать указатели в актуальный цвет.

В результате после завершения этой фазы всё встанет на свои места:

![Результат сборки мусора](https://habrastorage.org/r/w1560/getpro/habr/upload_files/095/e60/2c5/095e602c51af67a69049604effa24e1e.png "Результат сборки мусора")

Результат сборки мусора

## Полная сборка

Описанный алгоритм позволяет выполнять большую часть работы по сборке мусора не останавливая работу основных потоков приложения. Но он, конечно же, не гарантирует, что у приложения в любой момент есть достаточно свободной памяти.

При активном выделении памяти может возникнуть ситуация, когда у JVM не осталось свободных блоков для размещения новых объектов. В этом случае работа приложения останавливается (пауза STW) и, как и при использовании других сборщиков, запускается цикл полной сборки мусора. Здесь, конечно, речь о субмиллисекундных паузах уже не идет.

# Настройки JVM

HotSpot JVM предоставляет богатый набор параметров запуска (-X и -XX опции) для настройки поведения. Однако разработчику следует с осторожностью подходить к тюнингу – современные дефолты уже подходят для большинства случаев. Тем не менее, несколько ключевых областей настройки:

- **Память (Heap)**: как отмечалось, -Xmx задаёт максимум кучи, -Xms – начальный размер. По умолчанию максимум – небольшой процент от физической памяти (на серверных JVM ~25%). Для серверных приложений часто устанавливают -Xms равным -Xmx чтобы избежать постепенного роста. Также иногда увеличивают Metaspace, если приложение загружает много классов (-XX:MetaspaceSize / MaxMetaspaceSize).
- **Выбор GC**: флаги -XX:+UseG1GC (по умолчанию), +UseZGC, +UseShenandoahGC и др. Позволяют переключиться на нужный сборщик. Можно также регулировать связанные параметры (упомянутые выше).
- **JIT-компиляция**: обычно не требует вмешательства. В редких случаях отключают TieredCompilation (-XX:-TieredCompilation) – тогда используется только C2, или ограничивают уровень (-XX:TieredStopAtLevel=1 – только интерпретация и C1, без C2). Это бывает полезно для низкоресурсных сред или при отладке, но в боевых системах лучше оставлять по умолчанию. Можно управлять профилированием (флаги типа -XX:+PrintCompilation для логов JIT, -XX:CompileThreshold – пороги горячих методов, но трогать их без крайней необходимости не рекомендуется).
- **Другие флаги производительности**: например, -XX:+UseStringDeduplication (G1 умеет дедуплицировать строки в heap), -XX:+AlwaysPreTouch (протянуть память heap при старте, чтобы избежать мягких ошибках page fault на старте), -XX:+OptimizeStringConcat (оптимизация конкатенации строк), и множество других. Их воздействие минимально, либо уже включены по умолчанию, либо специфично.
 - **Размеры поколения**: для G1 можно задавать максимальный размер региона -XX:G1HeapRegionSize, для Parallel – долю young поколения -XX:NewRatio или абсолютный -Xmn. Чрезмерно маленький young может вызвать слишком частые Minor GC, а слишком большой – замедлить Major GC.
- **Паузы vs throughput**: G1 и другие имеют цели пауз (MaxGCPauseMillis). Уменьшая цель паузы, мы жертвуем throughput, т.к. GC будет разбивать работу на более мелкие части.
- **Concurrent циклы**: Shenandoah и ZGC практически не требуют тюнинга, но можно контролировать порог использования heap при котором начинается цикл (InitiatingHeapOccupancyPercent для Concurrent Mark).
- **Логирование GC**: крайне важный инструмент – флаг -Xlog:gc* (в Java 9+), включающий подробный лог сборок. Разработчик может анализировать длительность пауз, частоту, причины триггеров. Существуют утилиты (например, gceasy.io) для парсинга GC-логов.
- **Профилирование памяти**: с Java 11 доступен JDK Flight Recorder (о нём позже), который позволяет собирать события, включая данные по GC, распределениям объектах и т.д. Также jcmd утилита (jcmd GC.heap_info и др.) может вывести текущую статистику кучи.

# Процесс запуска JVM

![[Pasted image 20250823190145.png]]

Процесс запуска начинается с инициализации самой виртуальной машины. При вызове исполняемого файла `java` основная программа запуска вызывает функцию `JNI_CreateJavaVM()` из JNI-интерфейса. Эта функция создаёт экземпляр виртуальной машины и выполняет ряд важных шагов:

- **Валидация аргументов**: JVM проверяет входные параметры командной строки (флаги JVM, указание класса или jar-файла для запуска, classpath и пр.). Любые незнакомые или противоречивые опции вызовут ошибку ещё до запуска. С Java 9 формат опций был унифицирован (например, предупреждения при использовании deprecated-флагов). В debug-логе (-Xlog:arguments*) можно увидеть результат парсинга аргументов.
- **Детектирование ресурсов системы**: JVM определяет характеристики среды, на которой запущена. В частности, число доступных процессоров (ядер) для настройки внутренних потоков (например, GC-потоков), объём доступной памяти, размер страницы памяти, наличие/отсутствие определённых системных сервисов. Эти данные влияют, например, на выбор дефолтного GC (HotSpot может выбрать SerialGC на однопроцессорной машине) или количества потоков компиляции.
- **Подготовка среды исполнения**: HotSpot выполняет ряд внутренних инициализаций – резервирует память под Heap (согласно -Xms и т.д.), инициализирует основные структуры. Интересный факт: при старте HotSpot генерирует в памяти платформо-зависимый интерпретатор на основе шаблонов (Template Interpreter), т.е. фактически собирает низкоуровневый код для выполнения байт-кодов. Кроме того, на этом этапе JIT-компиляторы (C1, C2) загружаются и готовятся к работе: выделяют буферы, создают очереди задач. Если включена JVMCI, может загружаться JVMCI-компилятор (например, Graal, если бы он был подключён).
- **Выбор сборщика мусора**: во время старта принимается решение, какой GC будет активен. Хотя по умолчанию задан G1, JVM учитывает особые случаи. Например, в клиентском режиме на очень малой памяти может быть выбран SerialGC, или если указана опция -XX:+UseZGC – то ZGC. В логе (-Xlog:gc*) можно увидеть сообщение о выбранном сборщике. В Java 21 с добавлением Generational ZGC, если включить ZGC, то по умолчанию будет generational-режим (его можно отладочно переключать). Также JVM на старте рассчитывает размеры поколений, размер регионов (G1 автоматически подбирает размер региона на основе heap – обычно так, чтобы было ~2048 регионов).
- **Загрузка и маппинг архивов CDS**: очень важный шаг в современном запуске – Class Data Sharing (CDS). Начиная с JDK 9+, JVM поставляется с предсозданным архивом базовых классов (classes.jsa), который маппится в память при старте. В Java 21 CDS архив по умолчанию включен и содержит ~12 тыс. наиболее часто используемых классов Java SE. JVM пытается найти этот архив (в JDK) и загрузить сегмент с уже подготовленными образами классов. Это значительно ускоряет запуск, поскольку классы из архива не нужно парсить и верифицировать – они уже проверены. Если архив не найден или несовместим (бывает при изменении конфигурации), JVM продолжит без него. Также, если используется AppCDS (архив пользовательских классов, созданный заранее), он тоже подключается тут.
- **Создание Method Area (Metaspace)**: JVM выделяет первоначальный Metaspace (или PermGen в старых версиях). В HotSpot Metaspace размещается на нативной куче. На старте может быть выделен initial Metaspace (опция MetaspaceSize задаёт объём, после которого начнёт расти). Этот этап упомянут в описаниях как создание структуры method area.
- **Старт служебных потоков**: виртуальная машина запускает свои фоновые потоки: GC threads (для параллельного GC), JIT-compiler threads (C1/C2 компиляции), Signal handler thread (обрабатывает сигналы ОС), Attach Listener (для инструментов вроде jcmd), Periodic Tasks thread (занимается вспомогательными задачами). Все эти потоки запускаются прежде, чем начать выполнение кода пользователя.

Когда среда готова, JVM переходит к загрузке пользовательского класса с public static void main.

JVM получает от launcher-а имя класса или модуль и класс, который нужно запустить (например, MyApp из команды). Далее работает подсистема Class Loader:

- **Поиск и загрузка класса приложения**. Bootstrap ClassLoader начинает поиск указанного класса MyApp в предоставленном classpath (или modulepath, если используется модульная система). Если класс не модульный, то AppClassLoader (порождённый от Bootstrap) будет фактически читать файл MyApp.class. Предположим, MyApp находится в текущей директории или в jar – класс будет найден и считан. Байты .class загружаются в память, парсится структура (проверяется магическое число, версия, заголовки). На этом шаге создаётся объект класса Class внутри JVM, но он пока не полностью готов к использованию.
- **Решение зависимостей**. При загрузке MyApp JVM обнаруживает, от каких других классов он зависит. Например, любой класс Java неявно наследуется от java.lang.Object. Значит, перед тем как завершить загрузку MyApp, JVM должна убедиться, что загружен java.lang.Object, а также другие используемые типы (родители, интерфейсы, типы полей). В частности, если MyApp имеет метод public static void main(String[] args), то JVM потребуется загрузить класс java.lang.String (и его зависимости) прежде, чем запустить main. Таким образом, загрузка часто рекурсивно вытягивает цепочку классов. По логам (с -Xlog:class+load=info) можно увидеть, как JVM сначала грузит java.lang.Object, затем связанные интерфейсы, потом java.lang.String и т.д., прежде чем добраться до самого MyApp. К счастью, большинство базовых классов уже лежат в CDS архиве и их загрузка сводится к маппингу страницы памяти.
- **Верификация класса (часть связывания)**. После загрузки сырого байткода JVM проводит верификацию – проверяет корректность класса по ряду правил (типы, допустимость инструкций, правильность наследования и т.п.). Это критический этап безопасности – он гарантирует, что байт-код не нарушает высокоуровневую безопасность (например, не сможет произвольно записать в чужую область памяти). Верификация описана в спецификации (раздел 5.4.1) и включает проверку форматирования, семантическую проверку, контроль потоков выполнения (асм-уровня) на предмет корректности типов стека и т.д. Если класс не проходит проверку – получим VerifyError. В CDI-архиве классы уже считаются проверенными и подготовленными, поэтому стандартные классы обычно пропускают этот шаг во время старта, что ускоряет загрузку. Однако HelloWorld (наш класс) не из архива, значит JVM выполнит его полную верификацию (в логах это можно увидеть при включенном -Xlog:class+load).
- **Подготовка (Preparation)**. Далее выполняется фаза подготовки (spec 5.4.2): для загруженного класса выделяются и инициализируются статические поля базовыми значениями. Например, если в классе MyClass есть static int X = 10;, то на этапе подготовки JVM зарезервирует память под MyClass.X и установит значение по умолчанию (для int это 0). Инициализация присвоенным константам (10) пока не производится – это будет на следующем этапе (инициализация класса). Также JVM вычисляет размер объектов, смещения полей, готовит таблицы виртуальных методов.
- **Разрешение (Resolution)**. Этот подэтап (spec 5.4.3) может происходить как лениво, так и сразу. Разрешение означает перевод всех символьных ссылок в постоянные ссылки. В .class файле ссылки на другие классы, методы и поля хранятся в символьном виде (пул констант: имена, дескрипторы). JVM может по требованию разрешать их – т.е. находить соответствующий загруженный класс, метод и ставить прямой указатель. По стандарту, JVM волен откладывать resolution до первого использования. HotSpot обычно выполняет разрешение лениво: например, вызов метода не будет разрешён, пока не вызовется. Тем не менее, некоторые реализации (или режимы) могут разрешить всё сразу после загрузки. Для нашего рассмотрения достаточно знать, что когда main начнёт вызывать что-то, JVM уже к тому моменту загрузит и свяжет требуемые сущности.

После прохождения загрузки и связывания класс считается полностью загруженным и подготовленным. На него можно ссылаться, вызывать его методы (в том числе main). Но прежде чем выполнить метод main, JVM должна выполнить инициализацию класса.

Инициализация класса (spec 5.5) – финальная фаза жизни класса перед использованием. Здесь выполняются все его статические инициализаторы: присваиваются заданные значения статическим полям и исполняется блок static { ... } если присутствует. Инициализация происходит лениво: класс инициализируется при первом активном использовании (например, при первом обращении к любому статическому полю или методу класса). Для класса, содержащего метод public static void main, инициализация происходит непосредственно перед вызовом main. В нашем примере, MyApp имеет, возможно, статические поля – они получат указанные значения. Если есть статический блок – он выполнится.

Инициализация происходит под монитором класса (для гарантии потокобезопасности). Если класс A ссылается на неинициализированный B, то в процессе инициализации A JVM может инициализировать B (это называется инициализация по требованию). Порядок сложных сценариев детально описан в спецификации, но ключевое: JVM автоматически позаботится, что все нужные классы инициализированы в корректном порядке перед использованием.

После инициализации класса MyApp, JVM создаёт основной поток выполнения (т.н. “main” thread) и вызывает метод MyApp.main(String[] args). С этого момента начинается непосредственное выполнение пользовательского кода.

После вызова main() JVM переходит в режим обычного выполнения приложения. Далее уже включаются описанные ранее механизмы: методы постепенно JIT-компилируются, GC срабатывает по заполнению поколений, пользовательские потоки создаются и исполняются.

Важно, что сам процесс запуска JVM – весьма надёжный и отлаженный. Если на этапе старта происходит ошибка, как правило, это фатально (JVM не смогла запуститься или загрузить главный класс). Во время же выполнения большинство ошибок – следствие проблем приложения (NullPointerException и прочие), а JVM как платформа продолжает работать. Таким образом, этап запуска либо завершается успешно и приложение работает до нормального завершения, либо прерывается очень рано с сообщением об ошибке (например, класс не найден, VerifyError, OutOfMemory при инициализации, и т.д.).
# [[Оглавление]]